# 2024-4-16

## 回顾

- 把aicode vscode 插件的 inline-chat 功能，基本完成了，把昨天待处理问题2解决了
- 做了aicode vscode 插件的性能优化，今天走完了下面两个优化措施：
```
1. 在运维层面做代码补全的接口限流，一秒内只需要发送2个补全请求，超出自动取消
2. 在运维层面编写脚本，获取请求的ip列表，并找出存在异常行为的ip，如不停的调用补全接口
```

通过上述两个性能优化措施，可以一定程度降低模型侧算力的压力。

## 回家

- 用 bookmanize chrome 插件整理了下我的书签，分分类，该删的删

## 明日计划

1. 研究 llmcpp 和 llm cache
2. 给出 llmcpp 和 llm cache 的可行性方案


## 今日成长

[满分5颗星]

成长指数：:star::star::star::star::star:

- 系统实践了 vscode 插件的 inline chat 功能，短短一天就搞定了复杂度高且比较抽象的功能，具备强大的技术底蕴